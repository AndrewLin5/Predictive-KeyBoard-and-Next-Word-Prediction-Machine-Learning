{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5474f4-c082-4b72-ba70-2c09cf010738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\megaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\megaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "017949ba-16b2-40c4-8829-e70850bbdc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.2/376.0 MB 20.9 MB/s eta 0:00:18\n",
      "    --------------------------------------- 8.1/376.0 MB 20.1 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 12.6/376.0 MB 20.2 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 17.6/376.0 MB 20.9 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 22.5/376.0 MB 21.9 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 27.3/376.0 MB 21.9 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 33.8/376.0 MB 23.1 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 40.1/376.0 MB 23.8 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 47.7/376.0 MB 25.1 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 55.8/376.0 MB 26.3 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 64.0/376.0 MB 27.5 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 72.9/376.0 MB 28.7 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 80.7/376.0 MB 29.3 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 89.4/376.0 MB 30.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 99.4/376.0 MB 31.1 MB/s eta 0:00:09\n",
      "   ----------- --------------------------- 110.1/376.0 MB 32.2 MB/s eta 0:00:09\n",
      "   ------------ -------------------------- 120.8/376.0 MB 33.4 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 132.1/376.0 MB 34.4 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 143.7/376.0 MB 35.4 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 154.9/376.0 MB 36.3 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 162.5/376.0 MB 36.2 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 173.5/376.0 MB 36.8 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 177.7/376.0 MB 36.8 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 177.7/376.0 MB 36.8 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 184.5/376.0 MB 34.5 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 198.2/376.0 MB 35.6 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 217.1/376.0 MB 37.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 238.6/376.0 MB 39.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 251.7/376.0 MB 40.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 267.6/376.0 MB 42.6 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 282.3/376.0 MB 46.0 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 303.0/376.0 MB 50.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 325.3/376.0 MB 54.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 346.8/376.0 MB 59.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  370.7/376.0 MB 63.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 64.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 64.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 57.4 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 129.4 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB ? eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 22.3/26.4 MB 100.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 79.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 55.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-win_amd64.whl (307 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.2 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.9 opt-einsum-3.4.0 optree-0.15.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8049d583-a626-4079-a008-93eb76bfc123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 15.7/212.5 MB 99.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 24.6/212.5 MB 62.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 46.9/212.5 MB 78.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 69.5/212.5 MB 86.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 92.8/212.5 MB 92.5 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 118.0/212.5 MB 97.8 MB/s eta 0:00:01\n",
      "   ------------------------- ------------- 140.0/212.5 MB 99.4 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 163.1/212.5 MB 100.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ---- 187.4/212.5 MB 102.4 MB/s eta 0:00:01\n",
      "   -------------------------------------  211.3/212.5 MB 103.9 MB/s eta 0:00:01\n",
      "   -------------------------------------  212.3/212.5 MB 102.8 MB/s eta 0:00:01\n",
      "   -------------------------------------  212.3/212.5 MB 102.8 MB/s eta 0:00:01\n",
      "   -------------------------------------  212.3/212.5 MB 102.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 73.8 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 90.9 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 72.0 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 54.9 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f99056-81e6-46d9-a5c6-174d0dfbd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5deba886-b16b-4b95-ad58-c17f39b787eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc836959-7a89-4209-87c5-0b2baf272421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "with open('sherlock-holm.es_stories_plain-text_advs.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5d9dec-0430-4718-a779-bda57310c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 125772\n"
     ]
    }
   ],
   "source": [
    "#Print Tokens\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Total Tokens:\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c01eb66-e50b-4ab9-bf5c-dea3581914d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a dictionary to map a word and another to map the words back\n",
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(tokens)\n",
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c17f172-10a3-40f6-ba20-bb7dc03cb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input target sequences\n",
    "sequence_length = 4  # e.g., \"I am going to [predict this]\"\n",
    "\n",
    "data = []\n",
    "for i in range(len(tokens) - sequence_length):\n",
    "    input_seq = tokens[i:i + sequence_length - 1]\n",
    "    target = tokens[i + sequence_length - 1]\n",
    "    data.append((input_seq, target))\n",
    "\n",
    "# convert words to indices\n",
    "def encode(seq): return [word2idx[word] for word in seq]\n",
    "\n",
    "encoded_data = [(torch.tensor(encode(inp)), torch.tensor(word2idx[target]))\n",
    "                for inp, target in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e4343fd-22aa-4776-8126-adc739878e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design Model Architecture using Class\n",
    "class PredictiveKeyboard(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=128):\n",
    "        super(PredictiveKeyboard, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.fc(output[:, -1, :])  # last LSTM output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13f3f409-0c3d-45b2-9c58-1641919e250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8594b587-987d-478a-bbe7-abc1ee2aa0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 66130.8354\n",
      "Epoch 2, Loss: 68044.2236\n",
      "Epoch 3, Loss: 69431.4519\n",
      "Epoch 4, Loss: 71257.2095\n",
      "Epoch 5, Loss: 71353.2787\n",
      "Epoch 6, Loss: 72548.3559\n",
      "Epoch 7, Loss: 72651.3637\n",
      "Epoch 8, Loss: 74788.9088\n",
      "Epoch 9, Loss: 74966.7768\n",
      "Epoch 10, Loss: 74432.4795\n",
      "Epoch 11, Loss: 75721.6624\n",
      "Epoch 12, Loss: 78366.6934\n",
      "Epoch 13, Loss: 78033.9548\n",
      "Epoch 14, Loss: 78392.8573\n",
      "Epoch 15, Loss: 80387.2584\n",
      "Epoch 16, Loss: 80361.3355\n",
      "Epoch 17, Loss: 81650.4595\n",
      "Epoch 18, Loss: 80571.3293\n",
      "Epoch 19, Loss: 80528.8822\n",
      "Epoch 20, Loss: 80735.7273\n"
     ]
    }
   ],
   "source": [
    "model = PredictiveKeyboard(vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    random.shuffle(encoded_data)\n",
    "    for input_seq, target in encoded_data[:10000]:  # Limit data for speed\n",
    "        input_seq = input_seq.unsqueeze(0)\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target.unsqueeze(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "418dd841-1e1a-4bdc-a211-9acd91c75a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fd21807-4435-4d73-a1cf-6f7d97acbb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions: ['the', 'once', 'all']\n"
     ]
    }
   ],
   "source": [
    "#Predict words \n",
    "def suggest_next_words(model, text_prompt, top_k=3):\n",
    "    model.eval()\n",
    "    tokens = word_tokenize(text_prompt.lower())\n",
    "    if len(tokens) < sequence_length - 1:\n",
    "        raise ValueError(f\"Input should be at least {sequence_length - 1} words long.\")\n",
    "\n",
    "    input_seq = tokens[-(sequence_length - 1):]\n",
    "    input_tensor = torch.tensor(encode(input_seq)).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probs = F.softmax(output, dim=1).squeeze()\n",
    "        top_indices = torch.topk(probs, top_k).indices.tolist()\n",
    "\n",
    "    return [idx2word[idx] for idx in top_indices]\n",
    "\n",
    "print(\"Suggestions:\", suggest_next_words(model, \"So, are we really at\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b819a41b-005e-4518-bc69-952fb07bf53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting next words predictor with tokenizing words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a79d1907-4a58-470c-a5ef-3959a7822bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input-outpair pairs by splitting texts into sequences and using n-grams\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79be7ba3-4d48-4d33-b58e-397ac7955adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad input sequences with equal length\n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c4dd0f7-33ca-4ebf-9714-e9966c5936f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split sequences\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86ee0f59-e6ce-4cf2-a0cb-f3d435e030fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert output to one hot encoders\n",
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "263b5d84-e4e2-40b9-b774-fce2ec03a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\megaw\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">820,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8200</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,238,200</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m820,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m150,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8200\u001b[0m)                │       \u001b[38;5;34m1,238,200\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,208,800</span> (8.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,208,800\u001b[0m (8.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,208,800</span> (8.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,208,800\u001b[0m (8.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#Build neural network architecture to train model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100,input_shape=(max_sequence_len - 1,)))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4d31be5-8735-41cb-94cd-b541890f6d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 46ms/step - accuracy: 0.0622 - loss: 6.5514\n",
      "Epoch 2/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 47ms/step - accuracy: 0.1199 - loss: 5.5413\n",
      "Epoch 3/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 37ms/step - accuracy: 0.1485 - loss: 5.1327\n",
      "Epoch 4/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 37ms/step - accuracy: 0.1654 - loss: 4.7846\n",
      "Epoch 5/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 36ms/step - accuracy: 0.1869 - loss: 4.4522\n",
      "Epoch 6/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.2057 - loss: 4.1827\n",
      "Epoch 7/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 37ms/step - accuracy: 0.2332 - loss: 3.8915\n",
      "Epoch 8/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 37ms/step - accuracy: 0.2653 - loss: 3.6259\n",
      "Epoch 9/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.2975 - loss: 3.3781\n",
      "Epoch 10/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 37ms/step - accuracy: 0.3346 - loss: 3.1485\n",
      "Epoch 11/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 37ms/step - accuracy: 0.3717 - loss: 2.9332\n",
      "Epoch 12/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 38ms/step - accuracy: 0.4050 - loss: 2.7469\n",
      "Epoch 13/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.4419 - loss: 2.5569\n",
      "Epoch 14/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.4771 - loss: 2.3945\n",
      "Epoch 15/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.5027 - loss: 2.2522\n",
      "Epoch 16/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 36ms/step - accuracy: 0.5330 - loss: 2.1100\n",
      "Epoch 17/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.5623 - loss: 1.9809\n",
      "Epoch 18/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.5830 - loss: 1.8730\n",
      "Epoch 19/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 36ms/step - accuracy: 0.6104 - loss: 1.7530\n",
      "Epoch 20/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 36ms/step - accuracy: 0.6284 - loss: 1.6619\n",
      "Epoch 21/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.6491 - loss: 1.5800\n",
      "Epoch 22/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.6686 - loss: 1.4880\n",
      "Epoch 23/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 37ms/step - accuracy: 0.6868 - loss: 1.4045\n",
      "Epoch 24/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.7013 - loss: 1.3404\n",
      "Epoch 25/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 36ms/step - accuracy: 0.7157 - loss: 1.2693\n",
      "Epoch 26/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.7264 - loss: 1.2203\n",
      "Epoch 27/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.7407 - loss: 1.1634\n",
      "Epoch 28/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 38ms/step - accuracy: 0.7514 - loss: 1.1109\n",
      "Epoch 29/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.7588 - loss: 1.0688\n",
      "Epoch 30/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.7741 - loss: 1.0185\n",
      "Epoch 31/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 36ms/step - accuracy: 0.7801 - loss: 0.9801\n",
      "Epoch 32/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 36ms/step - accuracy: 0.7861 - loss: 0.9435\n",
      "Epoch 33/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 35ms/step - accuracy: 0.7945 - loss: 0.9132\n",
      "Epoch 34/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 36ms/step - accuracy: 0.7985 - loss: 0.8872\n",
      "Epoch 35/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8084 - loss: 0.8477\n",
      "Epoch 36/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8133 - loss: 0.8250\n",
      "Epoch 37/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8181 - loss: 0.8021\n",
      "Epoch 38/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8230 - loss: 0.7775\n",
      "Epoch 39/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 36ms/step - accuracy: 0.8288 - loss: 0.7531\n",
      "Epoch 40/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.8296 - loss: 0.7423\n",
      "Epoch 41/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 36ms/step - accuracy: 0.8329 - loss: 0.7237\n",
      "Epoch 42/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.8352 - loss: 0.7091\n",
      "Epoch 43/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8415 - loss: 0.6899\n",
      "Epoch 44/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 36ms/step - accuracy: 0.8455 - loss: 0.6711\n",
      "Epoch 45/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8488 - loss: 0.6549\n",
      "Epoch 46/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.8508 - loss: 0.6469\n",
      "Epoch 47/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 37ms/step - accuracy: 0.8503 - loss: 0.6380\n",
      "Epoch 48/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8523 - loss: 0.6299\n",
      "Epoch 49/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.8567 - loss: 0.6133\n",
      "Epoch 50/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8561 - loss: 0.6093\n",
      "Epoch 51/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.8564 - loss: 0.6079\n",
      "Epoch 52/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.8606 - loss: 0.5908\n",
      "Epoch 53/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 36ms/step - accuracy: 0.8628 - loss: 0.5800\n",
      "Epoch 54/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8599 - loss: 0.5839\n",
      "Epoch 55/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 36ms/step - accuracy: 0.8634 - loss: 0.5704\n",
      "Epoch 56/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5683\n",
      "Epoch 57/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8652 - loss: 0.5596\n",
      "Epoch 58/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8669 - loss: 0.5512\n",
      "Epoch 59/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 37ms/step - accuracy: 0.8666 - loss: 0.5517\n",
      "Epoch 60/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8680 - loss: 0.5389\n",
      "Epoch 61/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.8691 - loss: 0.5369\n",
      "Epoch 62/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8683 - loss: 0.5339\n",
      "Epoch 63/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8702 - loss: 0.5311\n",
      "Epoch 64/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.8695 - loss: 0.5321\n",
      "Epoch 65/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 37ms/step - accuracy: 0.8699 - loss: 0.5240\n",
      "Epoch 66/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 38ms/step - accuracy: 0.8719 - loss: 0.5182\n",
      "Epoch 67/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 38ms/step - accuracy: 0.8729 - loss: 0.5151\n",
      "Epoch 68/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 40ms/step - accuracy: 0.8726 - loss: 0.5129\n",
      "Epoch 69/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 38ms/step - accuracy: 0.8731 - loss: 0.5092\n",
      "Epoch 70/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 38ms/step - accuracy: 0.8734 - loss: 0.5091\n",
      "Epoch 71/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 38ms/step - accuracy: 0.8748 - loss: 0.5025\n",
      "Epoch 72/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 37ms/step - accuracy: 0.8761 - loss: 0.4991\n",
      "Epoch 73/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 38ms/step - accuracy: 0.8748 - loss: 0.4997\n",
      "Epoch 74/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 38ms/step - accuracy: 0.8756 - loss: 0.4984\n",
      "Epoch 75/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 38ms/step - accuracy: 0.8764 - loss: 0.4896\n",
      "Epoch 76/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 39ms/step - accuracy: 0.8746 - loss: 0.4967\n",
      "Epoch 77/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.8731 - loss: 0.4977\n",
      "Epoch 78/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 38ms/step - accuracy: 0.8778 - loss: 0.4852\n",
      "Epoch 79/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.8733 - loss: 0.4976\n",
      "Epoch 80/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 36ms/step - accuracy: 0.8769 - loss: 0.4804\n",
      "Epoch 81/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 38ms/step - accuracy: 0.8740 - loss: 0.4872\n",
      "Epoch 82/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.8769 - loss: 0.4856\n",
      "Epoch 83/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 36ms/step - accuracy: 0.8762 - loss: 0.4828\n",
      "Epoch 84/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 36ms/step - accuracy: 0.8772 - loss: 0.4815\n",
      "Epoch 85/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 35ms/step - accuracy: 0.8761 - loss: 0.4843\n",
      "Epoch 86/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 36ms/step - accuracy: 0.8747 - loss: 0.4828\n",
      "Epoch 87/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8781 - loss: 0.4725\n",
      "Epoch 88/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8779 - loss: 0.4686\n",
      "Epoch 89/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 38ms/step - accuracy: 0.8731 - loss: 0.4866\n",
      "Epoch 90/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37ms/step - accuracy: 0.8768 - loss: 0.4777\n",
      "Epoch 91/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8749 - loss: 0.4823\n",
      "Epoch 92/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.8746 - loss: 0.4791\n",
      "Epoch 93/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 36ms/step - accuracy: 0.8783 - loss: 0.4678\n",
      "Epoch 94/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 36ms/step - accuracy: 0.8787 - loss: 0.4688\n",
      "Epoch 95/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 35ms/step - accuracy: 0.8747 - loss: 0.4769\n",
      "Epoch 96/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.8750 - loss: 0.4781\n",
      "Epoch 97/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 36ms/step - accuracy: 0.8752 - loss: 0.4736\n",
      "Epoch 98/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 37ms/step - accuracy: 0.8769 - loss: 0.4709\n",
      "Epoch 99/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 37ms/step - accuracy: 0.8775 - loss: 0.4695\n",
      "Epoch 100/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 36ms/step - accuracy: 0.8773 - loss: 0.4724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e415241cd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4cae3fe-0a90-4669-8554-a907ba9f28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "I will leave if they were fastened and\n"
     ]
    }
   ],
   "source": [
    "#Next word Prediction output\n",
    "seed_text = \"I will leave if they\"\n",
    "next_words = 3\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582c6a7-6cff-4bbb-b38f-7200f2b46ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
